{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import gensim\n",
    "import re\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "vocab = json.load(open('../models/words/vocab.json'))\n",
    "for k in vocab.keys():\n",
    "    vocab[int(k)] = vocab.pop(k)\n",
    "\n",
    "inverted_vocab = json.load(open('../models/words/inverted_vocab.json'))\n",
    "\n",
    "meter = json.load(open('../models/words/meter.json'))\n",
    "inverted_meter = json.load(\\\n",
    "    open('../models/words/inverted_meter.json'))\n",
    "        \n",
    "word2vec = gensim.models.Word2Vec.load('../models/word2vec.bin')\n",
    "\n",
    "rhyme = json.load(open('../models/words/rhyme.json'))\n",
    "inverted_rhyme = json.load( \\\n",
    "    open('../models/words/inverted_rhyme.json'))\n",
    "\n",
    "pos = json.load(open('../models/words/pos.json'))\n",
    "inverted_pos = json.load( \\\n",
    "    open('../models/words/inverted_pos.json'))\n",
    "\n",
    "\n",
    "\n",
    "def end_next(prev_end):\n",
    "    \"\"\"\n",
    "    Find the next end word given previous, finding a similar word that\n",
    "    ends in stressed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        w, p = zip(*word2vec.most_similar(prev_end, topn=10))\n",
    "    except KeyError:\n",
    "        return np.random.choice(inverted_rhyme.keys())\n",
    "\n",
    "    w = list(w)\n",
    "    # Make sure it starts out with unstressed\n",
    "    ends = []\n",
    "    for word in w:\n",
    "        if word == prev_end:\n",
    "            continue\n",
    "        if word not in inverted_rhyme:\n",
    "            continue\n",
    "        ends.append(word)\n",
    "\n",
    "    return np.random.choice(ends)\n",
    "\n",
    "\n",
    "def end_next_volta(prev_end):\n",
    "    try:\n",
    "        w, p = zip(*word2vec.most_similar(positive=[\"rich\", prev_end], \\\n",
    "                                              negative=[\"poor\"], topn=10))\n",
    "    except KeyError:\n",
    "        return np.random.choice(inverted_rhyme.keys())\n",
    "        \n",
    "    w = list(w)\n",
    "    # Make sure it starts out with unstressed\n",
    "    ends = []\n",
    "    for word in w:\n",
    "        if word == prev_end:\n",
    "            continue\n",
    "        if word not in inverted_rhyme:\n",
    "            continue\n",
    "        ends.append(word)\n",
    "\n",
    "    return np.random.choice(ends)\n",
    "\n",
    "\n",
    "def end_next_rhyme(prev_rhyme):\n",
    "    \"\"\"\n",
    "    Find the next end word given previous, and a word that must rhyme \n",
    "    with it.\n",
    "    \"\"\"\n",
    "    ending = inverted_rhyme[prev_rhyme][0]\n",
    "        \n",
    "    rhymes = rhyme[ending]\n",
    "\n",
    "    threshold_similarity = 0.1\n",
    "    best_words = []\n",
    "    for r in rhymes:\n",
    "        if r == prev_rhyme:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word2vec.similarity(prev_rhyme, r)\n",
    "            if sim > threshold_similarity:\n",
    "                best_words.append(r)\n",
    "        except KeyError:\n",
    "            # probably a stopword\n",
    "            best_words.append(r)\n",
    "\n",
    "    if len(best_words) == 0:\n",
    "        return np.random.choice(rhymes)\n",
    "\n",
    "    return np.random.choice(best_words)\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Helper function to sample an index from a probability array\n",
    "    with np.errstate(divide='ignore'):\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "    \n",
    "        preds = np.log(preds) / temperature\n",
    "        \n",
    "        # Fix division by 0\n",
    "        preds[preds == np.inf] = 0\n",
    "\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds =  exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return np.argmax(np.random.multinomial(1, preds, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "def syl_count(w):\n",
    "    \"\"\"\n",
    "    Roughly counts the number of syllables in a word (use when \n",
    "    NLTK cannot find word in its vocabulary.\n",
    "    \"\"\"\n",
    "    word = w.lower()\n",
    "    word = word.translate(string.punctuation)\n",
    "    \n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    " \n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    " \n",
    "    # Remove trailing e's\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\":\n",
    "            pass\n",
    "        else:\n",
    "            disc+=1\n",
    "     \n",
    "    if word[-2:] == \"ed\" or word[-2:] == \"es\":\n",
    "        if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" \\\n",
    "            or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "        else:\n",
    "            disc+=1\n",
    "    \n",
    "    # Count consecutive vowels as one\n",
    "    numVowels = len(re.findall(r'[aeoui]+', word))\n",
    "    \n",
    "    # Consider a few exceptions I found from perusing data\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "        \n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    " \n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    " \n",
    "    if word[-3:] == \"ian\": \n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else:\n",
    "            syls+=1\n",
    "    \n",
    "    if word[:5] == \"where\":\n",
    "        disc += 1\n",
    "        \n",
    "    return max(numVowels - disc + syls, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 30\n",
      "----- Generating with end: eemed my flame to qualify\n"
     ]
    }
   ],
   "source": [
    "files = ['../data/shakespeare.txt']\n",
    "text = ''\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            #line = re.sub(r'[^\\w\\s]','',line)\n",
    "            line = re.sub(r'[^\\w\\'\\-\\s]','',line)\n",
    "            if len(line) > 0 and not line.isdigit():\n",
    "                text += line.lower() + '\\n'\n",
    "\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(text)))\n",
    "print('Total chars:', len(chars))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Encodes abab cdcd efef gg rhyme scheme \n",
    "rhyme_scheme = {0:2, 1:3, 4:6, 5:7, 8:10, 9:11, 12:13}\n",
    "\n",
    "seq_length = 40 # Window length\n",
    "\n",
    "# Ending sequence\n",
    "lines = text.split(\"\\n\")\n",
    "generated = np.random.choice([line[-25:] for line in lines])\n",
    "print('----- Generating with end: %s' % generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', \"'\", '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPCFraunhoferlab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:93: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "C:\\Users\\OPCFraunhoferlab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "C:\\Users\\OPCFraunhoferlab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "end_words = [''] * 14\n",
    "end_words[-1] = generated.split(' ')[-1]\n",
    "lst_word = end_words[-1]\n",
    "lst_word = re.sub(r'[^\\w\\'\\-\\s]','',lst_word)\n",
    "#lst_word = re.sub(r'[^\\w\\s]','',lst_word)\n",
    "end_words[-1] = lst_word\n",
    "\n",
    "for i in range(12, -1, -1):\n",
    "    if i in rhyme_scheme:\n",
    "        cur_word = end_words[rhyme_scheme[i]]\n",
    "        #cur_word = re.sub(r'[^\\w\\s]','',cur_word)\n",
    "        cur_word = re.sub(r'[^\\w\\'\\-\\s]','',cur_word)\n",
    "        end_words[i] = end_next_rhyme(cur_word)\n",
    "    elif i == 11:\n",
    "        end_words[i] = end_next_volta(lst_word)\n",
    "    elif i % 4 == 3:\n",
    "        end_words[i] = end_next(lst_word)\n",
    "    else:\n",
    "        end_words[i] = end_next(end_words[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feeling', 'trifle', 'watching', 'idle', 'age', 'only', 'rage', 'costly', 'can', 'scorn', 'forgotten', 'sworn', 'strong', 'long']\n"
     ]
    }
   ],
   "source": [
    "print(end_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(seq_length, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../weights/sonnet_20_64_backward_nopunc_except.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is subject our love sore than his feeling,\n",
      "or as you most tills thou art that trifle,\n",
      "and yet but those bountious as a watching,\n",
      "glass and whilst were o no love the idle.\n",
      "therefore and these but that in the age,\n",
      "not tenked even with his notis only,\n",
      "raven and or eyes to love and trues see rage,\n",
      "than nor to my most and to his costly.\n",
      "or for so gave but when i have now can,\n",
      "i have even but that in the whore scorn,\n",
      "but since o no and for but forgotten,\n",
      "theremore no live and yet but when i have sworn.\n",
      "against the hiner and might that with his strong,\n",
      "if thou must bright even if thine eyes long.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "line = ''\n",
    "sonnet = ''\n",
    "temperature = 0.75\n",
    "for i in range(14):\n",
    "    generated = ' ' + end_words[i]   \n",
    "    #generated = end_words[i]   \n",
    "    line = generated\n",
    "    generated = generated.ljust(seq_length - 1)\n",
    "    generated = generated + '\\n'\n",
    "    sequence = generated[::-1]\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, seq_length, len(chars)))\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = int_to_char[next_index]\n",
    "        \n",
    "        # Ignore special characters\n",
    "        if (next_char == '\\n'):\n",
    "            next_char = ' '\n",
    "\n",
    "        # Check syllables\n",
    "        if (next_char == ' '): \n",
    "            syls = sum([syl_count(str(w)) for w in line.split(' ')])\n",
    "            if syls >= 10:\n",
    "                break\n",
    "        \n",
    "        line = next_char + line\n",
    "        sequence = sequence[1:] + next_char\n",
    "        \n",
    "    if ((i + 1) % 4 == 0) or (i == 13):\n",
    "        line += '.\\n'\n",
    "    else:\n",
    "        line += ',\\n'\n",
    "        \n",
    "    sonnet = sonnet + line\n",
    "print(sonnet)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
