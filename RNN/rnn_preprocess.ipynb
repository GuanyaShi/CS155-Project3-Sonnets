{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Rhyme and Meter of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import cmudict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the words, but preserve apostrophes and hyphens in the same word, and ignore other punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('[\\w|\\'|-]+') # keep apostrophes and hyphens\n",
    "\n",
    "line_tokens = []\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if (line.isdigit()):\n",
    "            continue\n",
    "        if (len(line) > 0):\n",
    "            line = line.lower()\n",
    "            tokens = tokenizer.tokenize(line)\n",
    "            \n",
    "            line_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\OPCFraunhoferlab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import syl_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from', 'fairest', 'creatures', 'we', 'desire', 'increase']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter = {}\n",
    "rhyme = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the meter of the word, as well as its rhyme scheme, for use later on in improving poem generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    def syl(pronunciation):\n",
    "        return len([i[-1] for i in pronunciation if \\\n",
    "                i[-1].isdigit()])\n",
    "    \n",
    "    tot = 0\n",
    "    for word in line:\n",
    "        try:\n",
    "            pronounciation = d[word][0]\n",
    "            s = syl(pronounciation)\n",
    "            \n",
    "            sk = ','.join(pronounciation[-2:])\n",
    "            \n",
    "            if sk in rhyme.keys():\n",
    "                rhyme[sk].add(word)\n",
    "            else:\n",
    "                rhyme[sk] = set()\n",
    "                rhyme[sk].add(word)\n",
    "            \n",
    "        except (KeyError):\n",
    "            s = syl_count(word)\n",
    "        \n",
    "        stress = []\n",
    "        for i in xrange(s):\n",
    "            if (tot + i) % 2 == 0:\n",
    "                stress.append(0)\n",
    "            else:\n",
    "                stress.append(1)\n",
    "        \n",
    "        mk = ','.join(str(i) for i in stress)\n",
    "        if mk in meter.keys():\n",
    "            meter[mk].add(word)\n",
    "        else:\n",
    "            meter[mk] = set()\n",
    "            meter[mk].add(word)\n",
    "        \n",
    "        tot += s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a function to test how well cmudict can be used to find rhyming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rhymes(w):\n",
    "    entries = nltk.corpus.cmudict.entries()\n",
    "    syllables = [(word, syl) for word, syl in entries if word == w]\n",
    "    rhymes = []\n",
    "    for (word, syllable) in syllables:\n",
    "        rhymes += [word for word, pron in entries if pron[-2:] == syllable[-2:]]\n",
    "    return set(rhymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPCFraunhoferlab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lines(filename):\n",
    "    \"\"\"\n",
    "    Tokenizes the file and returns a list of tokens for\n",
    "    each line of poetry in the file.\n",
    "    \"\"\"\n",
    "    # Keep apostrophes and hyphens\n",
    "    tokenizer = RegexpTokenizer('\\w[\\w|\\'|-]+\\w') \n",
    "\n",
    "    line_tokens = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if (line.isdigit()):\n",
    "                continue\n",
    "            if (len(line) > 0):\n",
    "                line = line.lower()\n",
    "                tokens = tokenizer.tokenize(line)\n",
    "                \n",
    "                line_tokens.append(tokens)\n",
    "\n",
    "    return line_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../data/shakespeare.txt']\n",
    "\n",
    "line_tokens = []\n",
    "for filename in files:\n",
    "    line_tokens.extend(split_lines(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2155"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(line.strip() for line in open('../data/stopwords_elizabethan.txt'))\n",
    "\n",
    "for i in range(len(line_tokens)):\n",
    "    line_tokens[i] = [w for w in line_tokens[i] if not w in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fairest', 'creatures', 'desire', 'increase']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(line_tokens, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPCFraunhoferlab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('minded', 0.32648536562919617),\n",
       " (\"age's\", 0.32527804374694824),\n",
       " ('over-partial', 0.32107672095298767),\n",
       " ('blood', 0.31354910135269165),\n",
       " ('worth', 0.30000483989715576),\n",
       " ('statute', 0.2892206609249115),\n",
       " ('darling', 0.28607383370399475),\n",
       " ('instant', 0.2831827402114868),\n",
       " ('wondrous', 0.2809654474258423),\n",
       " ('swart-complexioned', 0.27310237288475037)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it on lines with a more complex neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fairest', 'creatures', 'desire', 'increase']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(line_tokens, size=300, window=8, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPCFraunhoferlab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dear', 0.2538563907146454),\n",
       " ('trial', 0.19950351119041443),\n",
       " ('forward', 0.18596231937408447),\n",
       " ('live', 0.1843087077140808),\n",
       " ('gentle', 0.17888158559799194),\n",
       " ('statute', 0.17387929558753967),\n",
       " ('pine', 0.17382600903511047),\n",
       " ('touches', 0.17281505465507507),\n",
       " ('give', 0.16968515515327454),\n",
       " ('world', 0.16774418950080872)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks a bit more accurate with a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/word2vec.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to find the most similar word that still rhymes, and is in our Shakespearean vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('../models/word2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhymes = find_rhymes(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPCFraunhoferlab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "max_similarity = 0.\n",
    "best_word = None\n",
    "for rhyme in rhymes:\n",
    "    if rhyme == \"love\":\n",
    "        continue\n",
    "    try:\n",
    "        if model.similarity(\"love\", rhyme) > max_similarity:\n",
    "            best_word = rhyme\n",
    "            max_similarity = model.similarity(\"love\", rhyme)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
