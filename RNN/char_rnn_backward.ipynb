{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../data/shakespeare.txt'] \n",
    "text = ''\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = re.sub(r'[^\\w\\'\\-\\s]','',line)\n",
    "            #line = re.sub(r'[^\\w\\s]','',line)\n",
    "\n",
    "            if len(line) > 0 and not line.isdigit():\n",
    "                text += line.lower() + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', \"'\", '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Total Characters:  91006\n",
      "Total Vocab:  30\n"
     ]
    }
   ],
   "source": [
    "print(chars)\n",
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  45483\n"
     ]
    }
   ],
   "source": [
    "# Train rnn from backward, setting the last word for rhyme first\n",
    "\n",
    "# generate train data from backward\n",
    "\n",
    "seq_length = 40\n",
    "step = 2\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, n_chars - seq_length, step):\n",
    "    seq_in = text[i + seq_length: i: -1]\n",
    "    seq_out = text[i]\n",
    "    sentences.append(seq_in)\n",
    "    next_chars.append(seq_out)\n",
    "n_patterns = len(sentences)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['esaercni erised ew serutaerc tseriaf mor', 't\\nesaercni erised ew serutaerc tseriaf m', 'aht\\nesaercni erised ew serutaerc tseriaf', ' taht\\nesaercni erised ew serutaerc tseri', 'ht taht\\nesaercni erised ew serutaerc tse', 'reht taht\\nesaercni erised ew serutaerc t', 'bereht taht\\nesaercni erised ew serutaerc', ' ybereht taht\\nesaercni erised ew serutae', 'eb ybereht taht\\nesaercni erised ew serut', 'uaeb ybereht taht\\nesaercni erised ew ser']\n",
      "['f', 'o', ' ', 'a', 'r', 's', ' ', 'r', 'a', 'u']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0:10])\n",
    "print(next_chars[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary\n",
    "X = np.zeros((len(sentences), seq_length, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(seq_length, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45483/45483 [==============================] - 165s 4ms/step - loss: 2.5404\n",
      "Epoch 2/20\n",
      "45483/45483 [==============================] - 182s 4ms/step - loss: 2.0394\n",
      "Epoch 3/20\n",
      "45483/45483 [==============================] - 183s 4ms/step - loss: 1.8712\n",
      "Epoch 4/20\n",
      "45483/45483 [==============================] - 181s 4ms/step - loss: 1.7433\n",
      "Epoch 5/20\n",
      "45483/45483 [==============================] - 180s 4ms/step - loss: 1.6476\n",
      "Epoch 6/20\n",
      "45483/45483 [==============================] - 181s 4ms/step - loss: 1.5738\n",
      "Epoch 7/20\n",
      "45483/45483 [==============================] - 179s 4ms/step - loss: 1.5073\n",
      "Epoch 8/20\n",
      "45483/45483 [==============================] - 180s 4ms/step - loss: 1.4377\n",
      "Epoch 9/20\n",
      "45483/45483 [==============================] - 179s 4ms/step - loss: 1.3730\n",
      "Epoch 10/20\n",
      "45483/45483 [==============================] - 181s 4ms/step - loss: 1.3078\n",
      "Epoch 11/20\n",
      "45483/45483 [==============================] - 183s 4ms/step - loss: 1.2443\n",
      "Epoch 12/20\n",
      "45483/45483 [==============================] - 181s 4ms/step - loss: 1.1815\n",
      "Epoch 13/20\n",
      "45483/45483 [==============================] - 182s 4ms/step - loss: 1.1096\n",
      "Epoch 14/20\n",
      "45483/45483 [==============================] - 181s 4ms/step - loss: 1.0339\n",
      "Epoch 15/20\n",
      "45483/45483 [==============================] - 182s 4ms/step - loss: 0.9764\n",
      "Epoch 16/20\n",
      "45483/45483 [==============================] - 183s 4ms/step - loss: 0.9098\n",
      "Epoch 17/20\n",
      "45483/45483 [==============================] - 184s 4ms/step - loss: 0.8504\n",
      "Epoch 18/20\n",
      "45483/45483 [==============================] - 182s 4ms/step - loss: 0.7955\n",
      "Epoch 19/20\n",
      "45483/45483 [==============================] - 181s 4ms/step - loss: 0.7519\n",
      "Epoch 20/20\n",
      "45483/45483 [==============================] - 184s 4ms/step - loss: 0.7018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cf1c2027b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=64, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('../weights/sonnet_20_64_backward_nopunc.h5')\n",
    "model.save_weights('../weights/sonnet_20_64_backward_nopunc_except.h5')\n",
    "#model.load_weights('../weights/sonnet_25_64_backward.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature = 1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "\n",
    "    preds = np.asarray(preds).astype('float')\n",
    "    preds = np.log(preds) / temperature\n",
    "\n",
    "    # Fix division by 0\n",
    "    preds[preds == np.inf] = 0\n",
    "\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds =  exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return np.argmax(np.random.multinomial(1, preds, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temperature = 0.75\n",
      "\n",
      "shall i compare thee to a summer's day \n",
      "of this\n",
      "peccused prive this it my give love's ture bow\n",
      "and yet beleives all wid words of more\n",
      "when thimed and mine uspiting of thee hore\n",
      "if thou my love that i i behold and true\n",
      "the summored words on love's longer writed\n",
      "whilst the smore must in the breddoms well\n",
      "my should loves to be distreds on my friend\n",
      "and being on enced and pends not enfited\n",
      "to this shadow pends not give time to suite\n",
      "for thily like pon of thee bemore\n",
      "to love to thee i make my love and love\n",
      "but in the lowks and intureous and looks\n",
      "and liven in the ourse looks trup kindness\n",
      "with thise pervention give thou art of thee\n",
      "mine i must to trespention can to write\n",
      "o none doth lives etercal winter end\n",
      "best can sinwed beauty from thee me cold\n",
      "make me where thou art love is my love to one\n",
      "to my side to this this thou lov'st come\n",
      "shall i compare thee to a summer's day \n",
      "\n",
      "\n",
      "temperature = 0.25\n",
      "\n",
      "shall i compare thee to a summer's day \n",
      " loves in my love where alone\n",
      "sweet love but in the beauties best pasied night\n",
      "and yet to thee where is my love's face\n",
      "me fromed of that for his goons more might\n",
      "to thee my love love's gracious and live\n",
      "that be depleired for my friended and\n",
      "theremore more bath in surest my self and love\n",
      "and lives my heart of mine on this this art\n",
      "tores on my love lives do not love my verse\n",
      "so recon it best be sure is to his spriving\n",
      "that faces of forth in wortly fears to love\n",
      "when i not envised in thine effence\n",
      "that my pespised and lives my lovely night\n",
      "kindness of most prices of heavers might\n",
      "o let my keep invention fears\n",
      "and loves not yet love is my love to more\n",
      "more more more more smore that the oummer's nite\n",
      "for that sweet loves not loves to thee hold live\n",
      "and live and thee to make my love not take me\n",
      "shall i compare thee to a summer's day \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "char_length = 800  # genrated length\n",
    "for temperature in [0.75, 0.25]:\n",
    "    print('\\n' + 'temperature = ' + str(temperature) + '\\n')\n",
    "    \n",
    "    generated = 'shall i compare thee to a summer\\'s day \\n'\n",
    "    #generated = 'summers                                ' +'\\n'\n",
    "    sentence = generated[::-1]\n",
    "    \n",
    "    sys.stdout.write(generated)\n",
    "    for i in range(char_length):\n",
    "        x = np.zeros((1, seq_length, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = int_to_char[next_index]\n",
    "\n",
    "        generated = next_char + generated\n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
